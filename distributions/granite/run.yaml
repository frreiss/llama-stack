version: '2'
image_name: granite
docker_image: null
conda_env: local
apis:
- shields
- agents
- models
- memory
- memory_banks
- inference
- safety
providers:
  inference:
  - provider_id: inline::meta-reference
    provider_type: inline::meta-reference
    config:
      model: Llama3.2-11B-Vision-Instruct
      torch_seed: null
      max_seq_len: 4096
      max_batch_size: 1
      create_distributed_process_group: true
      checkpoint_dir: null
  - provider_id: inline::granite
    provider_type: inline::granite
    config:
      modeldir: dmf_models
      backend: vllm
      preload_model_name: granite-3.0-8b-instruct-r241014a
  safety:
  - provider_id: inline::llama-guard
    provider_type: inline::llama-guard
    config:
      excluded_categories: []
  agents:
  - provider_id: inline::meta-reference
    provider_type: inline::meta-reference
    config: 
      persistence_store:
        namespace: null
        type: sqlite
        db_path: ~/.llama/runtime/kvstore.db
  memory:
  - provider_id: inline::faiss
    provider_type: inline::faiss
    config:
      kvstore:
        namespace: null
        type: sqlite
        db_path: ~/.llama/runtime/kvstore.db
  datasetio:
  - provider_id: inline::localfs
    provider_type: inline::localfs
    config: {}
  scoring:
  - provider_id: inline::basic
    provider_type: inline::basic
    config: {}
  eval:
  - provider_id: inline::meta-reference
    provider_type: inline::meta-reference
    config:
      kvstore:
        namespace: null
        type: sqlite
        db_path: ~/.llama/runtime/kvstore.db
metadata_store: null
models: 
- model_id: Llama3.2-11B-Vision-Instruct
  provider_id: inline::meta-reference
  provider_model_id: Llama3.2-11B-Vision-Instruct
- model_id: granite-3.0-8b-instruct-r241014a
  provider_id: inline::granite
  provider_model_id: granite-3.0-8b-instruct-r241014a
shields: []
memory_banks: []
datasets: []
scoring_fns: []
eval_tasks: []
